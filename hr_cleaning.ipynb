{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HR Data Cleaning Pipeline\n",
        "\n",
        "This notebook documents the end-to-end HR dataset preparation workflow using the reusable `hr_data_insights` Python package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Ensure the repository root is on the Python path so the package inside `src/` can be imported.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "SRC_PATH = PROJECT_ROOT / 'src'\n",
        "if str(SRC_PATH) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC_PATH))\n",
        "\n",
        "print(f'Project root: {PROJECT_ROOT}')\n",
        "print(f'Source path appended: {SRC_PATH}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Cleaning Pipeline\n",
        "The pipeline loads the raw dataset, standardises key fields, validates the result, and persists a cleaned CSV along with analytical tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from hr_data_insights.config import DatasetConfig\n",
        "from hr_data_insights.pipeline import run_pipeline\n",
        "\n",
        "config = DatasetConfig()\n",
        "raw_path = PROJECT_ROOT / config.input_path\n",
        "if not raw_path.exists():\n",
        "    print(f'\u26a0\ufe0f Raw dataset not found at {raw_path}. Place the file and re-run this cell.')\n",
        "else:\n",
        "    pipeline_result = run_pipeline(config=config)\n",
        "    cleaned_df = pipeline_result['cleaned']\n",
        "    print(f'Cleaned dataframe has {len(cleaned_df):,} rows and {cleaned_df.shape[1]} columns.')\n",
        "    if pipeline_result['validation_messages']:\n",
        "        print('Validation warnings:')\n",
        "        for msg in pipeline_result['validation_messages']:\n",
        "            print(f' - {msg}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preview the Cleaned Dataset\n",
        "A quick glance at the first rows, types, and summary statistics helps confirm the cleaning output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'cleaned_df' in globals():\n",
        "    display(cleaned_df.head())\n",
        "    display(cleaned_df.describe(include='all').transpose())\n",
        "else:\n",
        "    print('Pipeline has not been executed yet.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analytics Tables\n",
        "When the pipeline runs with metrics enabled (default), the primary HR business questions are returned as tidy dataframes for downstream BI tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'pipeline_result' in globals() and pipeline_result['analytics']:\n",
        "    for name, table in pipeline_result['analytics'].items():\n",
        "        print(f'\n=== {name} ===')\n",
        "        if isinstance(table, dict):\n",
        "            for sub_name, sub_table in table.items():\n",
        "                print(f'-- {sub_name} --')\n",
        "                display(sub_table.head())\n",
        "        else:\n",
        "            display(table.head() if hasattr(table, 'head') else table)\n",
        "else:\n",
        "    print('Analytics not computed yet.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}